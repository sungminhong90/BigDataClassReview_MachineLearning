{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DropOut.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B0NUZjOVpPs",
        "colab_type": "text"
      },
      "source": [
        "## 03 MNIST - DROPOUT 추가\n",
        "\n",
        "### 학습 내용\n",
        "* dropout 이해와 실습해 보기\n",
        "\n",
        "### 01 Dropout(드롭아웃) 설명\n",
        "* 과적합의 이해 - 학습한 결과가 학습 데이터에는 매우 잘 맞지만, 학습 데이터에만 너무 꼭 맞춰져 있어, 그\n",
        "외의 데이터에는 잘 맞지 않음.\n",
        "* 학습시 전체 신경망 중 일부만을 사용하도록 하는 것.\n",
        "* 즉, 학습 단계마다 일부 뉴런을 제거(사용하지 않도록)함으로써, 일부 특징이 특정 뉴런에 고정되는 것을 막\n",
        "아 가중치의 균형을 잡도록 한다.\n",
        "* 학습 시 일부 뉴런을 학습시키지 않기 때문에 신경망이 충분히 학습되기까지의 시간은 조금 더 오래 걸리는\n",
        "편이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0LrKrkPV7TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84xU4S1LWL4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JE4AXgPWPnv",
        "colab_type": "code",
        "outputId": "a63dc8f6-1854-44a3-842f-eb2f776e7a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets ('./mnist/data', one_hot = True)\n",
        "type(mnist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-e6283404bcf7>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJZylJ3SWWSH",
        "colab_type": "code",
        "outputId": "e584dc20-e7cf-4ba7-9e82-d898b8d26303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 데이터의 개수\n",
        "print(mnist.test.num_examples, mnist.train.num_examples, mnist.validation.num_examples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000 55000 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeNgWD9dWnM3",
        "colab_type": "code",
        "outputId": "52c70164-1c94-4e4d-cc0c-750546bd9385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 데이터의 행열 사이즈\n",
        "print(mnist.train.labels.shape, mnist.train.images.shape)\n",
        "print(mnist.test.labels.shape, mnist.test.images.shape)\n",
        "print(mnist.validation.labels.shape, mnist.validation.images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 10) (55000, 784)\n",
            "(10000, 10) (10000, 784)\n",
            "(5000, 10) (5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3me_IdDW6Bg",
        "colab_type": "text"
      },
      "source": [
        "## 01-02 신경망 모델 구성하기\n",
        "* MNIST의 손글씨는 28 X 28로 구성되어 있다.\n",
        "* 784개의 특징(픽셀)로 구성되어 있음.\n",
        "* 레이블은 0~9까지의 10개의 분류\n",
        "\n",
        "###Placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6HSTC87XAR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJITq7SeXFUX",
        "colab_type": "text"
      },
      "source": [
        "## 미니배치의 이해\n",
        "* 이미지를 하나씩 학습시키는 것보다 여러 개를 한꺼번에 학습시키는 쪽이 효과가 좋다.\n",
        "* 많은 메모리와 높은 컴퓨터 성능이 필요하므로 일반적으로 데이터를 적당한 크기로 잘라서 학습시킨다.이를 미니배치라고 한다.\n",
        "\n",
        "\n",
        "* tf.float32, [None, 784] => None의 자리에는 한번에 학습시킬 이미지의 개수를 지정하는 값이 들어감., 즉 배\n",
        "치 크기를 지정하는 자리이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r3e-rSmXSaX",
        "colab_type": "text"
      },
      "source": [
        "## 신경망의 구성\n",
        "* 입력층 - 784(입력, 특징 개수) ->\n",
        "  256(첫번째 은닉층 뉴런) ->\n",
        "  256(두번째 은닉층 뉴런)\n",
        "  출력층 -> 10(결과값 0~9 분류 개수 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1bErgs0XYn_",
        "colab_type": "text"
      },
      "source": [
        "## DROPOUT 적용\n",
        "- tf.nn.dropout(Layer, 비율)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtISQX28Xdfn",
        "colab_type": "code",
        "outputId": "5b1df1c0-b620-4e29-baf4-4b9ef46595dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, keep_prob) # means dropout\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob) # 뒤의뉴런을 0.8만 이용/학습시 해당 계층의 80%만이용 => 뒤에정의됨\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "print(W3)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-5208d2a90e9e>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "<tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>\n",
            "Tensor(\"MatMul_2:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYyHWcyTYgPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 이제 비용함수/최적하 함수 지정해주어야 한다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MjpZEP9YoD3",
        "colab_type": "text"
      },
      "source": [
        "## 비용함수, 최적화 함수 지정\n",
        "- AdamOptimizer (Adaptive Moment Estimation)은 RMSProp와 Momentum방식을 합친 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmBYrGuzYr9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels =Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZELPi8uZN1-",
        "colab_type": "text"
      },
      "source": [
        "## 세션 생성 및 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzkirC3WZQr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsjwP486ZVZ_",
        "colab_type": "text"
      },
      "source": [
        "## 배치 사이즈 지증\n",
        "\n",
        "- Mini-batch 크기가 전체 트레이닝 셋 데이터 사이즈인 m과 같다면 이것은 Batch gradient descent방법\n",
        " - 데이터가 별로 없다면 batch gradient descent를 사용\n",
        "- Mini-batch 크기가 1이라면 Stochastic gradient descent라고 한다.\n",
        " - 적은 메모리로 동작가능\n",
        " - 64,128, 256, 512 사이즈 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDCs0ZjlZg-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg_lEnxbaLYe",
        "colab_type": "text"
      },
      "source": [
        "## 학습\n",
        "- 학습 데이터 전체를 한 바퀴 도는 일을 에포크(Epoch)라 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYT24Z2ZaSFZ",
        "colab_type": "code",
        "outputId": "dfa4b7e4-67dd-403e-cbb3-01bba3b4d65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# MNIST 데이터 전체를 학습하는 일을 15번 반복함.\n",
        "# 학습 데이터 전체를 한 바퀴를 도는 일을 에포크(epoch)라 한다.\n",
        "\n",
        "for epoch in range(15):\n",
        "  total_cost = 0\n",
        "    \n",
        "  for i in range(total_batch):\n",
        "      #배치 사이즈만큼 데이터 가져오기\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "      #입력값: batch_xs, 출력값: batch_ys\n",
        "      #최적화를 수행 후 손실을 구한다.\n",
        "      _, cost_val = sess.run([optimizer, cost],\n",
        "                            feed_dict = {X: batch_xs, Y:batch_ys,\n",
        "                                        keep_prob : 0.8})\n",
        "      \n",
        "      # 총 손실 계산\n",
        "      total_cost = total_cost + cost_val\n",
        "      \n",
        "  print('Epoch: %4d' %(epoch+1), '평균 Cost = ', '{:.2f}'.format(total_cost/total_batch))\n",
        "\n",
        "    \n",
        "print('최적화 완료!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    1 평균 Cost =  0.43\n",
            "Epoch:    2 평균 Cost =  0.17\n",
            "Epoch:    3 평균 Cost =  0.11\n",
            "Epoch:    4 평균 Cost =  0.09\n",
            "Epoch:    5 평균 Cost =  0.07\n",
            "Epoch:    6 평균 Cost =  0.06\n",
            "Epoch:    7 평균 Cost =  0.05\n",
            "Epoch:    8 평균 Cost =  0.05\n",
            "Epoch:    9 평균 Cost =  0.04\n",
            "Epoch:   10 평균 Cost =  0.04\n",
            "Epoch:   11 평균 Cost =  0.03\n",
            "Epoch:   12 평균 Cost =  0.03\n",
            "Epoch:   13 평균 Cost =  0.03\n",
            "Epoch:   14 평균 Cost =  0.03\n",
            "Epoch:   15 평균 Cost =  0.02\n",
            "최적화 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Y9sy8qabc-",
        "colab_type": "text"
      },
      "source": [
        "## 정확도 확인\n",
        "- argmax : 가장 큰 값의 갖는 인덱스를 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTXfupQ8cabN",
        "colab_type": "code",
        "outputId": "56d6aa22-68e9-47cb-c329-7b362f6075c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 모델의 예측값과 실제값을 비교한다.\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "is_correct\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: ', sess.run(accuracy,\n",
        "                       feed_dict = {X: mnist.test.images,\n",
        "                                   Y: mnist.test.labels,\n",
        "                                   keep_prob: 0.8}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도:  0.9767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9MVjTvPc218",
        "colab_type": "text"
      },
      "source": [
        "## 과적합을 막아주는 기법으로 가장 유명한 것 (드롭아웃)\n",
        "## 다른 과적합 방지 방법\n",
        "- 배치 정규화(Batch Normalization) : Gradient Vanishing/Gradient Exploding 이 일어나지 않도록 하기 위한\n",
        "방법\n",
        "  - 기존의 해결방법 : Activation 함수의 변화(ReLU등), 주의깊은 initialization, 작은 small learning rate\n",
        "2015년 발표 논문\n",
        "  - 아래 두 함수를 이용하여 적용이 가능하다.\n",
        "- tf.nn.batch_normalization\n",
        "- tf.layers.batch_normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9twXqQpdATm",
        "colab_type": "code",
        "outputId": "23916e11-e996-4a53-cea2-b3ec8ea044e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels = sess.run(model, feed_dict = {X: mnist.test.images,\n",
        "                                     Y: mnist.test.labels,\n",
        "                                     keep_prob :0.8})\n",
        "\n",
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TELGAKWydIkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpyxfPEddMlV",
        "colab_type": "code",
        "outputId": "ae996eb1-8bb4-48db-a64a-8fbce35d3317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "for i in range(10):\n",
        "  subplot = fig.add_subplot(2,5, i+1)\n",
        "  \n",
        "  # 이미지 깨끗하게 출력, x, y의 눈금 출력 안함.\n",
        "  subplot.set_xticks([])\n",
        "  subplot.set_yticks([])\n",
        "  \n",
        "  subplot.set_title('{}'.format(np.argmax(labels[i])))\n",
        "  subplot.imshow(mnist.test.images[i].reshape((28,28)),\n",
        "          cmap=plt.cm.gray_r)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADSCAYAAAB9/7r8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niERCA7KISCQ0IIuIROL/AWUvVQZhcCILAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npOG_X2mdzaT",
        "colab_type": "text"
      },
      "source": [
        "## 더 알아보기\n",
        "- 과적합을 막아주는 기법으로 가장 유명한 것이 쉽게 이해 가능한 것은 드롭아웃이다.\n",
        "- 최근에는 배치 정규화(Batch Normalization)라는 기법이 많이 이용됨.\n",
        "  - 과적합을 막고, 학습 속도도 향상시켜주는 장점이 있다.\n",
        "  - 등장 배경은 학습 시 발산이나 소실 등을 방지하여 학습 속도를 높이기 위한 방법이다.\n",
        "  - tf.nn.batch_normalization과 tf.layers.batch_normalization 함수로 쉽게 적용 가능."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VikoSk_5d7Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}